{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5114674452354135\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "from args_parameter import args\n",
    "from PrepareData import ACCESS_BARRA_v1\n",
    "import xarray as xr\n",
    "\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "file_ACCESS_dir=\"/g/data/ub7/access-s1/hc/raw_model/atmos/pr/daily/\"\n",
    "file_BARRA_dir=\"/g/data/ma05/BARRA_R/analysis/acum_proc/\"\n",
    "# ensemble=['e01','e02']\n",
    "ensemble=['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11']\n",
    "access_rgb_mean= 2.9067910245780248e-05*86400\n",
    "\n",
    "leading_time=217\n",
    "leading_time_we_use=31\n",
    "\n",
    "\n",
    "init_date=date(1970, 1, 1)\n",
    "start_date=date(1990, 1, 2)\n",
    "end_date=date(1990,12,30) #if 929 is true we should substract 1 day\n",
    "dates=[start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "print(access_rgb_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5114674452354135\n"
     ]
    }
   ],
   "source": [
    "#for debuging on my computer\n",
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "from args_parameter import args\n",
    "from PrepareData import ACCESS_BARRA_v1\n",
    "\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "import utility\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import xarray as xr\n",
    "\n",
    "file_ACCESS_dir=\"F:/climate/access-s1/pr/daily/\"\n",
    "file_BARRA_dir=\"C:/Users/JIA059/barra/\"\n",
    "\n",
    "# ensemble=['e01','e02']\n",
    "ensemble=['e01','e02']\n",
    "access_rgb_mean= 2.9067910245780248e-05*86400\n",
    "\n",
    "leading_time=217\n",
    "leading_time_we_use=31\n",
    "\n",
    "\n",
    "init_date=date(1970, 1, 1)\n",
    "start_date=date(1990, 1, 2)\n",
    "end_date=date(2018,12,31) #if 929 is true we should substract 1 day\n",
    "dates=[start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "print(access_rgb_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "#     transforms.Resize(IMG_SIZE),\n",
    "#     transforms.RandomResizedCrop(IMG_SIZE),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(30),\n",
    "    transforms.ToTensor()\n",
    "#     transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "])\n",
    "\n",
    "data_set=ACCESS_BARRA_v1(start_date,end_date,transform=train_transforms)\n",
    "train_data,test_data=random_split(data_set,[int(len(data_set)*0.8),len(data_set)-int(len(data_set)*0.8)])\n",
    "\n",
    "\n",
    "len(train_data)\n",
    "# len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "train_dataloders =DataLoader(train_data,\n",
    "                                        batch_size=8,\n",
    "                                        shuffle=False)\n",
    "test_dataloders =DataLoader(test_data,\n",
    "                                        batch_size=8,\n",
    "                                        shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model...\n",
      "accesss-s1 mean (0.4690, 0.4490, 0.4036)\n"
     ]
    }
   ],
   "source": [
    "args.cpu=True\n",
    "# args.pre_train =False\n",
    "# args.pre_train =\"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model/RCAN_BIX\"+str(args.scale[0])+\".pt\"\n",
    "# \"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model\"\n",
    "def prepare( l, volatile=False):\n",
    "    device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "    def _prepare(tensor):\n",
    "        if args.precision == 'half': tensor = tensor.half()\n",
    "        return tensor.to(device)\n",
    "\n",
    "    return [_prepare(_l) for _l in l]\n",
    "\n",
    "checkpoint = utility.checkpoint(args)\n",
    "net = model.Model(args, checkpoint).double()\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer_my = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "training_name=\"temp01\"\n",
    "\n",
    "max_error=10000\n",
    "for e in range(args.epochs):\n",
    "    start=time.time()\n",
    "    if e % 10 == 0:\n",
    "        for p in optimizer_my.param_groups:\n",
    "            p['lr'] *= 0.9\n",
    "\n",
    "    for batch, (lr, hr,_,_) in enumerate(train_dataloders):\n",
    "    #     print(batch, (lr.size(), hr.size()))\n",
    "        lr, hr = prepare([lr, hr])\n",
    "        optimizer_my.zero_grad()\n",
    "        sr = net(lr, 0)\n",
    "        error = criterion(sr[:,:,:,0:403], hr)\n",
    "        if error<max_error:\n",
    "            max_error=error\n",
    "            torch.save(net,\"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model\"+str(e)+\".pkl\")\n",
    "#             if not os.path.exists(\"./model/save/temp01/\"):\n",
    "#                 os.mkdir(\"./model/save/temp01/\")\n",
    "#             torch.save(net,\"./model/save/\"+training_name+\"/\"+str(e)+\".pkl\")\n",
    "\n",
    "        error.backward()\n",
    "        optimizer_my.step()\n",
    "        break\n",
    "#     print(\"epoche: %d,time cost %f s, lr: %f, error: %f\"%(e,time.time()-start,optimizer_my.state_dict()['param_groups'][0]['lr'],error.item()))\n",
    "        \n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.shape,hr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ef63eb2181d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#testing,and evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeasure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompare_ssim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeasure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompare_psnr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcompare_mse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "#testing,and evaluation\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net.eval()\n",
    "start=time.time()\n",
    "with torch.no_grad():\n",
    "    eval_acc=0\n",
    "    tqdm_test = tqdm(test_dataloders, ncols=80)\n",
    "    for idx_img, (lr, hr,date,_) in enumerate(tqdm_test):\n",
    "        print(date)\n",
    "        lr, hr = prepare([lr, hr])\n",
    "        sr = net(lr, 0)\n",
    "        print(compare_psnr(sr,hr,hr.max()-hr.min()))\n",
    "#         hr_numpy=hr.numpy()[][0]\n",
    "#         hr_numpy=np.ascontiguousarray(hr_numpy.transpose((1, 0)))\n",
    "#         data_hr=xr.DataArray(hr_numpy,coords=[data_set.lon.data,data_set.lat.data],dims=[\"lat\",\"lon\"])\n",
    "        \n",
    "#         print(date)\n",
    "#         dpt.draw_aus(data_hr,\n",
    "#              colormap = plt.cm.get_cmap('RdBu_r', 10),\n",
    "#              title=\"super resolution we predicted\",\n",
    "#              save=False)\n",
    "        \n",
    "        \n",
    "#         sr = utility.quantize(sr, self.args.rgb_range)\n",
    "\n",
    "        break\n",
    "print(\"time cost: %f s \"%(start-time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sr.shape,hr.shape)\n",
    "# calc_psnr(sr,hr,4,1200)\n",
    "# data_set.lon.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo:\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    import time\n",
    "    start=time.time()\n",
    "    print(\"test time for sigle day %s \" %(time.time()-start))\n",
    "\n",
    "    sr_numpy=sr.numpy()[7][0]\n",
    "#     sr_numpy=np.ascontiguousarray(sr_numpy.transpose((1, 0)))\n",
    "    data_sr=xr.DataArray(sr_numpy,coords=[data_set.lat.data,data_set.lon.data],dims=[\"lat\",\"lon\"])\n",
    "    \n",
    "    hr_numpy=hr.numpy()[7][0]\n",
    "#     hr_numpy=np.ascontiguousarray(hr_numpy.transpose((1, 0)))\n",
    "    data_hr=xr.DataArray(hr_numpy,coords=[data_set.lat.data,data_set.lon.data],dims=[\"lat\",\"lon\"])\n",
    "    print(date)\n",
    "    dpt.draw_aus(data_hr,\n",
    "                 colormap = plt.cm.get_cmap('RdBu_r', 10),\n",
    "                 title=\"super resolution we predicted\",\n",
    "                 save=False)\n",
    "    dpt.draw_aus(data_sr,\n",
    "                 colormap = plt.cm.get_cmap('RdBu_r', 10),\n",
    "                 title=\"super resolution we predicted\",\n",
    "                 save=False)\n",
    "\n",
    "# psnr1(sr, hr)\n",
    "# print(hr.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hr_numpy.shape)\n",
    "print(data_set.lon.data.shape)\n",
    "print(data_set.lat.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "\n",
    "\n",
    "\n",
    "epoch = self.scheduler.last_epoch + 1\n",
    "self.ckp.write_log('\\nEvaluation:')\n",
    "self.ckp.add_log(torch.zeros(1, len(self.scale)))\n",
    "self.model.eval()\n",
    "\n",
    "timer_test = utility.timer()\n",
    "with torch.no_grad():\n",
    "    for idx_scale, scale in enumerate(self.scale):\n",
    "        eval_acc = 0\n",
    "        self.loader_test.dataset.set_scale(idx_scale)\n",
    "        tqdm_test = tqdm(self.loader_test, ncols=80)\n",
    "        for idx_img, (lr, hr, filename, _) in enumerate(tqdm_test):\n",
    "            filename = filename[0]\n",
    "            no_eval = (hr.nelement() == 1)\n",
    "            if not no_eval:\n",
    "                lr, hr = self.prepare([lr, hr])\n",
    "            else:\n",
    "                lr = self.prepare([lr])[0]\n",
    "\n",
    "            sr = self.model(lr, idx_scale)\n",
    "            sr = utility.quantize(sr, self.args.rgb_range)\n",
    "\n",
    "            save_list = [sr]\n",
    "            if not no_eval:\n",
    "                eval_acc += utility.calc_psnr(\n",
    "                    sr, hr, scale, self.args.rgb_range,\n",
    "                    benchmark=self.loader_test.dataset.benchmark\n",
    "                )\n",
    "                save_list.extend([lr, hr])\n",
    "\n",
    "            if self.args.save_results:\n",
    "                self.ckp.save_results(filename, save_list, scale)\n",
    "\n",
    "        self.ckp.log[-1, idx_scale] = eval_acc / len(self.loader_test)\n",
    "        best = self.ckp.log.max(0)\n",
    "        self.ckp.write_log(\n",
    "            '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
    "                self.args.data_test,\n",
    "                scale,\n",
    "                self.ckp.log[-1, idx_scale],\n",
    "                best[0][idx_scale],\n",
    "                best[1][idx_scale] + 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "self.ckp.write_log(\n",
    "    'Total time: {:.2f}s\\n'.format(timer_test.toc()), refresh=True\n",
    ")\n",
    "if not self.args.test_only:\n",
    "    self.ckp.save(self, epoch, is_best=(best[1][0] + 1 == epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.new()\n",
    "np.random.rand(8, 4, 78, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel=1\n",
    "# x=np.random.rand(8,channel, 78, 100)\n",
    "# x=x.astype(np.float32)\n",
    "# print(x.dtype)\n",
    "\n",
    "# means, stdevs = [], []\n",
    "\n",
    "# for i in range(channel):\n",
    "#     pixels = x[:, i, :, :].ravel()  # 拉成一行\n",
    "#     means.append(np.mean(pixels))\n",
    "#     stdevs.append(np.std(pixels))\n",
    "\n",
    "# x=torch.tensor(x)\n",
    "\n",
    "\n",
    "# # std=np.std(x.ravel(),axis=0)\n",
    "# # print(std.shape)\n",
    "# # mean=np.mean(x)\n",
    "# print(means)\n",
    "# print(stdevs)\n",
    "\n",
    "# # x=torch.rand((8, 3, 78, 100))\n",
    "# # std=torch.std(x)\n",
    "# # mean=torch.mean(x)\n",
    "\n",
    "# # x.dtype=\"float32\"\n",
    "\n",
    "# class MeanShift(nn.Conv2d):\n",
    "#     def __init__(self, rgb_range, rgb_mean, rgb_std,channels, sign=-1):\n",
    "#         super(MeanShift, self).__init__(channel, channel, kernel_size=1)\n",
    "#         std = torch.Tensor(rgb_std)\n",
    "#         self.weight.data = torch.eye(channel).view(channel, channel, 1, 1)\n",
    "#         self.weight.data.div_(std.view(channel, 1, 1, 1))\n",
    "#         self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean)\n",
    "#         self.bias.data.div_(std)\n",
    "#         self.requires_grad = False\n",
    "        \n",
    "# aa=MeanShift(1,means,stdevs,3)\n",
    "# # aa(x)\n",
    "# np.mean(aa(x).detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checkpoint = utility.checkpoint(args)\n",
    "# # net = model.Model(args, checkpoint)\n",
    "# # criterion = nn.L1Loss()\n",
    "# # optimizer_my = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
    "# def prepare( l, volatile=False):\n",
    "#     device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "#     def _prepare(tensor):\n",
    "#         if args.precision == 'half': tensor = tensor.half()\n",
    "#         return tensor.to(device)\n",
    "\n",
    "#     return [_prepare(_l) for _l in l]\n",
    "\n",
    "# max_error=10000\n",
    "# for e in range(args.epochs):\n",
    "#     if e % 10 == 0:\n",
    "#         for p in optimizer_my.param_groups:\n",
    "#             p['lr'] *= 0.9\n",
    "        \n",
    "#     net.train()\n",
    "#     for batch, (lr, hr) in enumerate(train_dataloders):\n",
    "#         lr, hr = prepare([lr, hr])\n",
    "# #         print(lr)\n",
    "\n",
    "#         optimizer_my.zero_grad()\n",
    "#         sr = net(lr, 0)\n",
    "# #         sr=utility.fit_size(sr,args)\n",
    "\n",
    "#         error = criterion(sr[:,:,:,0:403], hr)\n",
    "#         if error<max_error:\n",
    "#             max_error=error\n",
    "#             torch.save(net,\"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model/save/\"+str(e)+\".pkl\")\n",
    "#         error.backward()\n",
    "#         optimizer_my.step()\n",
    "#     print(\"epoche: %d, lr: %f, error: %f\"%(e,optimizer_my.state_dict()['param_groups'][0]['lr'],error.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
