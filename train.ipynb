{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5114674452354135\n",
      "training statistics:\n",
      "  ------------------------------\n",
      "  trainning name  |  temp01\n",
      "  ------------------------------\n",
      "  num of channels |     1\n",
      "  ------------------------------\n",
      "  num of threads  |     8\n",
      "  ------------------------------\n",
      "  batch_size      |    16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "from args_parameter import args\n",
    "from PrepareData import ACCESS_BARRA_v1,ACCESS_BARRA_v2\n",
    "\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "import utility\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import xarray as xr\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "\n",
    "args.file_ACCESS_dir_pr=\"/g/data/ub7/access-s1/hc/raw_model/atmos/pr/daily/\"\n",
    "args.file_ACCESS_dir=\"/g/data/ub7/access-s1/hc/raw_model/atmos/\"\n",
    "# training_name=\"temp01\"\n",
    "args.file_BARRA_dir=\"/g/data/ma05/BARRA_R/v1/forecast/spec/accum_prcp/\"\n",
    "args.channels=0\n",
    "if args.pr:\n",
    "    args.channels+=1\n",
    "if args.dem:\n",
    "    args.channels+=1\n",
    "if args.zg:\n",
    "    args.channels+=1\n",
    "if args.psl:\n",
    "    args.channels+=1\n",
    "if args.tasmax:\n",
    "    args.channels+=1\n",
    "if args.tasmin:\n",
    "    args.channels+=1\n",
    "access_rgb_mean= 2.9067910245780248e-05*86400\n",
    "\n",
    "leading_time=217\n",
    "args.leading_time_we_use=7\n",
    "args.ensemble=2\n",
    "\n",
    "init_date=date(1970, 1, 1)\n",
    "start_date=date(1990, 1, 2)\n",
    "# end_date=date(2012,12,25) #if 929 is true we should substract 1 day\n",
    "dates=[start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "print(access_rgb_mean)\n",
    "\n",
    "print(\"training statistics:\")\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  trainning name  |  %s\"%args.train_name)\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  num of channels | %5d\"%args.channels)\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  num of threads  | %5d\"%args.n_threads)\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  batch_size      | %5d\"%args.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5114674452354135\n",
      "training statistics:\n",
      "  ------------------------------\n",
      "  trainning name  |  temp01\n",
      "  ------------------------------\n",
      "  num of channels |     1\n",
      "  ------------------------------\n",
      "  num of threads  |     8\n",
      "  ------------------------------\n",
      "  batch_size      |    16\n"
     ]
    }
   ],
   "source": [
    "#for debuging on my computer\n",
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "from args_parameter import args\n",
    "from PrepareData import ACCESS_BARRA_v1,ACCESS_BARRA_v2\n",
    "\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "import utility\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import xarray as xr\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "\n",
    "args.file_ACCESS_dir=\"E:/climate/access-s1/\"\n",
    "# args.file_ACCESS_dir=\"H:/climate/access-s1/\"\n",
    "\n",
    "args.file_BARRA_dir=\"C:/Users/JIA059/barra/\"\n",
    "# args.file_BARRA_dir=\"D:/dataset/accum_prcp/\"\n",
    "\n",
    "args.channels=1\n",
    "args.batch_size=16\n",
    "\n",
    "# ensemble=['e01','e02']\n",
    "args.ensemble=2\n",
    "access_rgb_mean= 2.9067910245780248e-05*86400\n",
    "\n",
    "leading_time=217\n",
    "args.leading_time_we_use=7\n",
    "# args.lr=0.001\n",
    "\n",
    "init_date=date(1970, 1, 1)\n",
    "start_date=date(1990, 1, 2)\n",
    "end_date=date(1990,12,25) #if 929 is true we should substract 1 day\n",
    "dates=[start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "print(access_rgb_mean)\n",
    "print(\"training statistics:\")\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  trainning name  |  %s\"%args.train_name)\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  num of channels | %5d\"%args.channels)\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  num of threads  | %5d\"%args.n_threads)\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  batch_size      | %5d\"%args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> BARRA_R & ACCESS_S1 loading\n",
      "=> from 1990/01/02 to 1990/12/25\n",
      "C:/Users/JIA059/barra/\n",
      "no file or no permission!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Dataset statistics:\n",
      "  ------------------------------\n",
      "  total |   603\n",
      "  ------------------------------\n",
      "  train |   482\n",
      "  ------------------------------\n",
      "  val   |   121\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "#     transforms.Resize(IMG_SIZE),\n",
    "#     transforms.RandomResizedCrop(IMG_SIZE),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(30),\n",
    "    transforms.ToTensor()\n",
    "#     transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "])\n",
    "\n",
    "data_set=ACCESS_BARRA_v2(start_date,end_date,transform=train_transforms,args=args)\n",
    "train_data,val_data=random_split(data_set,[int(len(data_set)*0.8),len(data_set)-int(len(data_set)*0.8)])\n",
    "\n",
    "\n",
    "print(\"Dataset statistics:\")\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  total | %5d\"%len(data_set))\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  train | %5d\"%len(train_data))\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  val   | %5d\"%len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloders =DataLoader(train_data,\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0)\n",
    "val_dataloders =DataLoader(val_data,\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False,\n",
    "                           num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model...\n",
      "accesss-s1 mean (0.4690)\n"
     ]
    }
   ],
   "source": [
    "args.cpu=True\n",
    "# args.pre_train =False\n",
    "# args.pre_train =\"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model/RCAN_BIX\"+str(args.scale[0])+\".pt\"\n",
    "# \"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model\"\n",
    "def prepare( l, volatile=False):\n",
    "    device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "    def _prepare(tensor):\n",
    "        if args.precision == 'half': tensor = tensor.half()\n",
    "        return tensor.to(device)\n",
    "\n",
    "    return [_prepare(_l) for _l in l]\n",
    "\n",
    "checkpoint = utility.checkpoint(args)\n",
    "net = model.Model(args, checkpoint).double()\n",
    "args.lr=0.001\n",
    "criterion = nn.L1Loss()\n",
    "optimizer_my = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer_my, step_size=7, gamma=0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_my, gamma=0.9)\n",
    "# torch.optim.lr_scheduler.MultiStepLR(optimizer_my, milestones=[20,80], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, args, ckp):\n",
    "        super(Model, self).__init__()\n",
    "        print('Making model...')\n",
    "\n",
    "        self.scale = args.scale\n",
    "        self.idx_scale = 0\n",
    "        self.self_ensemble = args.self_ensemble\n",
    "        self.chop = args.chop\n",
    "        self.precision = args.precision\n",
    "        self.cpu = args.cpu\n",
    "        self.device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "        self.n_GPUs = args.n_GPUs\n",
    "        self.save_models = args.save_models\n",
    "\n",
    "        module = import_module('model.' + args.model.lower())\n",
    "        self.model = module.make_model(args).to(self.device)\n",
    "        if args.precision == 'half': self.model.half()\n",
    "\n",
    "        if not args.cpu and args.n_GPUs > 1:\n",
    "            ckp.my_write_log(\"Let's use\"+str(torch.cuda.device_count())+\"GPUs!\")\n",
    "            self.model = nn.DataParallel(self.model, range(args.n_GPUs))\n",
    "\n",
    "        self.load(\n",
    "            ckp.dir,\n",
    "            pre_train=args.pre_train,\n",
    "            resume=args.resume,\n",
    "            cpu=args.cpu\n",
    "        )\n",
    "        if args.print_model: print(self.model)\n",
    "\n",
    "    def forward(self, x, idx_scale):\n",
    "        self.idx_scale = idx_scale\n",
    "        target = self.get_model()\n",
    "        if hasattr(target, 'set_scale'):\n",
    "            target.set_scale(idx_scale)\n",
    "\n",
    "        if self.self_ensemble and not self.training:\n",
    "            if self.chop:\n",
    "                forward_function = self.forward_chop\n",
    "            else:\n",
    "                forward_function = self.model.forward\n",
    "\n",
    "            return self.forward_x8(x, forward_function)\n",
    "        elif self.chop and not self.training:\n",
    "            return self.forward_chop(x)\n",
    "        else:\n",
    "            return self.model(x)\n",
    "\n",
    "    def get_model(self):\n",
    "        if self.n_GPUs == 1:\n",
    "            return self.model\n",
    "        else:\n",
    "            return self.model\n",
    "            return self.model.module\n",
    "\n",
    "    def state_dict(self, **kwargs):\n",
    "        target = self.get_model()\n",
    "        return target.state_dict(**kwargs)\n",
    "\n",
    "    def save(self, apath, epoch, is_best=False):\n",
    "        target = self.get_model()\n",
    "        torch.save(\n",
    "            target.state_dict(), \n",
    "            os.path.join(apath, 'model', 'model_latest.pt')\n",
    "        )\n",
    "        if is_best:\n",
    "            torch.save(\n",
    "                target.state_dict(),\n",
    "                os.path.join(apath, 'model', 'model_best.pt')\n",
    "            )\n",
    "        else:\n",
    "            torch.save(\n",
    "                target.state_dict(),\n",
    "                os.path.join(apath, 'model', 'model_{}.pt'.format(epoch))\n",
    "            )\n",
    "        \n",
    "        if self.save_models:\n",
    "            torch.save(\n",
    "                target.state_dict(),\n",
    "                os.path.join(apath, 'model', 'model_{}.pt'.format(epoch))\n",
    "            )\n",
    "\n",
    "    def load(self, apath, pre_train='.', resume=-1, cpu=False):\n",
    "        if cpu:\n",
    "            kwargs = {'map_location': lambda storage, loc: storage}\n",
    "        else:\n",
    "            kwargs = {}\n",
    "\n",
    "        if resume == -1:\n",
    "            self.get_model().load_state_dict(\n",
    "                torch.load(\n",
    "                    os.path.join(apath, 'model', 'model_latest.pt'),\n",
    "                    **kwargs\n",
    "                ),\n",
    "                strict=False\n",
    "            )\n",
    "        elif resume == 0:\n",
    "            if pre_train != '.':\n",
    "                print('Loading model from {}'.format(pre_train))\n",
    "                self.get_model().load_state_dict(\n",
    "                    torch.load(pre_train, **kwargs),\n",
    "                    strict=False\n",
    "                )\n",
    "        else:\n",
    "            self.get_model().load_state_dict(\n",
    "                torch.load(\n",
    "                    os.path.join(apath, 'model', 'model_{}.pt'.format(resume)),\n",
    "                    **kwargs\n",
    "                ),\n",
    "                strict=False\n",
    "            )\n",
    "    # shave = 10, min_size=160000\n",
    "    def forward_chop(self, x, shave=10, min_size=160000):\n",
    "        scale = self.scale[self.idx_scale]\n",
    "        n_GPUs = min(self.n_GPUs, 4)\n",
    "        b, c, h, w = x.size()\n",
    "        h_half, w_half = h // 2, w // 2\n",
    "        h_size, w_size = h_half + shave, w_half + shave\n",
    "        lr_list = [\n",
    "            x[:, :, 0:h_size, 0:w_size],\n",
    "            x[:, :, 0:h_size, (w - w_size):w],\n",
    "            x[:, :, (h - h_size):h, 0:w_size],\n",
    "            x[:, :, (h - h_size):h, (w - w_size):w]]\n",
    "\n",
    "        if w_size * h_size < min_size:\n",
    "            sr_list = []\n",
    "            for i in range(0, 4, n_GPUs):\n",
    "                lr_batch = torch.cat(lr_list[i:(i + n_GPUs)], dim=0)\n",
    "                sr_batch = self.model(lr_batch)\n",
    "                sr_list.extend(sr_batch.chunk(n_GPUs, dim=0))\n",
    "        else:\n",
    "            sr_list = [\n",
    "                self.forward_chop(patch, shave=shave, min_size=min_size) \\\n",
    "                for patch in lr_list\n",
    "            ]\n",
    "\n",
    "        h, w = scale * h, scale * w\n",
    "        h_half, w_half = scale * h_half, scale * w_half\n",
    "        h_size, w_size = scale * h_size, scale * w_size\n",
    "        shave *= scale\n",
    "\n",
    "        output = x.new(b, c, h, w)\n",
    "        output[:, :, 0:h_half, 0:w_half] \\\n",
    "            = sr_list[0][:, :, 0:h_half, 0:w_half]\n",
    "        output[:, :, 0:h_half, w_half:w] \\\n",
    "            = sr_list[1][:, :, 0:h_half, (w_size - w + w_half):w_size]\n",
    "        output[:, :, h_half:h, 0:w_half] \\\n",
    "            = sr_list[2][:, :, (h_size - h + h_half):h_size, 0:w_half]\n",
    "        output[:, :, h_half:h, w_half:w] \\\n",
    "            = sr_list[3][:, :, (h_size - h + h_half):h_size, (w_size - w + w_half):w_size]\n",
    "\n",
    "        return output\n",
    "\n",
    "    def forward_x8(self, x, forward_function):\n",
    "        def _transform(v, op):\n",
    "            if self.precision != 'single': v = v.float()\n",
    "\n",
    "            v2np = v.data.cpu().numpy()\n",
    "            if op == 'v':\n",
    "                tfnp = v2np[:, :, :, ::-1].copy()\n",
    "            elif op == 'h':\n",
    "                tfnp = v2np[:, :, ::-1, :].copy()\n",
    "            elif op == 't':\n",
    "                tfnp = v2np.transpose((0, 1, 3, 2)).copy()\n",
    "\n",
    "            ret = torch.Tensor(tfnp).to(self.device)\n",
    "            if self.precision == 'half': ret = ret.half()\n",
    "\n",
    "            return ret\n",
    "\n",
    "        lr_list = [x]\n",
    "        for tf in 'v', 'h', 't':\n",
    "            lr_list.extend([_transform(t, tf) for t in lr_list])\n",
    "\n",
    "        sr_list = [forward_function(aug) for aug in lr_list]\n",
    "        for i in range(len(sr_list)):\n",
    "            if i > 3:\n",
    "                sr_list[i] = _transform(sr_list[i], 't')\n",
    "            if i % 4 > 1:\n",
    "                sr_list[i] = _transform(sr_list[i], 'h')\n",
    "            if (i % 4) % 2 == 1:\n",
    "                sr_list[i] = _transform(sr_list[i], 'v')\n",
    "\n",
    "        output_cat = torch.cat(sr_list, dim=0)\n",
    "        output = output_cat.mean(dim=0, keepdim=True)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end loading one data,time cost 2.676250\n",
      "end loading one data,time cost 3.161077\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7d0a6ae2ef24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mrunning_loss\u001b[0m \u001b[1;31m#.copy()?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mrunning_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer_my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "\n",
    "max_error=np.inf\n",
    "for e in range(args.epochs):\n",
    "    #train\n",
    "    net.train()\n",
    "    loss=0\n",
    "    start=time.time()\n",
    "#     if e % 10 == 0:\n",
    "#         for p in optimizer_my.param_groups:\n",
    "#             p['lr'] *= 0.9\n",
    "\n",
    "    for batch, (lr, hr,_,_) in enumerate(train_dataloders):\n",
    "    #     print(batch, (lr.size(), hr.size()))\n",
    "        lr, hr = prepare([lr, hr])\n",
    "        optimizer_my.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            sr = net(lr, 0)\n",
    "#         error = criterion(sr[:,:,:,0:403], hr)\n",
    "            running_loss =criterion(sr, hr)\n",
    "            loss+=running_loss #.copy()?\n",
    "        running_loss.backward()\n",
    "        optimizer_my.step()\n",
    "        \n",
    "    #validation\n",
    "    net.eval()\n",
    "    start=time.time()\n",
    "    with torch.no_grad():\n",
    "        eval_psnr=0\n",
    "        eval_ssim=0\n",
    "        tqdm_val = tqdm(val_dataloders, ncols=80)\n",
    "        for idx_img, (lr, hr,date,_) in enumerate(tqdm_val):\n",
    "            lr, hr = prepare([lr, hr])\n",
    "            sr = net(lr, 0)\n",
    "            val_loss=criterion(sr, hr)\n",
    "            for ssr,hhr in zip(sr,hr):\n",
    "                eval_psnr+=compare_psnr(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "                eval_ssim+=compare_ssim(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )      \n",
    "#             print(\"psnr: %f \"%(eval_psnr/len(test_data)))\n",
    "    print(\"epoche: %d,time cost %f s, lr: %f, train_loss: %f,validation loss:%f \"%(\n",
    "              e,\n",
    "              time.time()-start,\n",
    "              optimizer_my.state_dict()['param_groups'][0]['lr'],\n",
    "              loss.item()/len(train_data),\n",
    "              val_loss\n",
    "         ))\n",
    "    if running_loss<max_error:\n",
    "        max_error=running_loss\n",
    "#         torch.save(net,train_loss\"_\"+str(e)+\".pkl\")\n",
    "        if not os.path.exists(\"./model/save/\"+args.train_name+\"/\"):\n",
    "            os.mkdir(\"./model/save/\"+args.train_name+\"/\")\n",
    "        torch.save(net,\"./model/save/\"+args.train_name+\"/\"+str(e)+\".pkl\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.train_name=\"temp02\"\n",
    "if not os.path.exists(\"./model/save/\"+args.train_name+\"/\"):\n",
    "    os.mkdir(\"./model/save/\"+args.train_name+\"/\")\n",
    "# torch.save(net,\"./model/save/\"+training_name+\"/\"+str(e)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing,and evaluation\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net.eval()\n",
    "start=time.time()\n",
    "with torch.no_grad():\n",
    "    eval_psnr=0\n",
    "    eval_ssim=0\n",
    "    tqdm_val = tqdm(val_dataloders, ncols=80)\n",
    "    for idx_img, (lr, hr,date,_) in enumerate(tqdm_val):\n",
    "        lr, hr = prepare([lr, hr])\n",
    "        sr = net(lr, 0)\n",
    "        val_loss=criterion(sr, hr)\n",
    "        for ssr,hhr in zip(sr,hr):\n",
    "            eval_psnr+=compare_psnr(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "            eval_ssim+=compare_ssim(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "            \n",
    "            \n",
    "            \n",
    "        break\n",
    "#     break\n",
    "            \n",
    "    print(\"psnr: %f \"%(eval_psnr/len(val_data)))\n",
    "        \n",
    "print(\"time cost: %f s \"%(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (len(test_dataloders)*args.batch_size )\n",
    "print(0+val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hr.max()-hr.min()).item()\n",
    "print(\"psnr: %f \"%(hr.max()-hr.min()).item() )\n",
    "ssim_avg=0\n",
    "psnr_avg=0\n",
    "for ssr,hhr in zip(sr,hr):\n",
    "#     print(hhr[0].shape)\n",
    "#     print(compare_ssim(ssr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() ))\n",
    "    psnr_avg+=compare_psnr(ssr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() )\n",
    "    ssim_avg+=compare_ssim(ssr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() )\n",
    "print(ssim_avg/args.batch_size)\n",
    "print(psnr_avg/args.batch_size)\n",
    "compare_psnr(ssr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() )\n",
    "\n",
    "print(args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sr.shape,hr.shape)\n",
    "compare_psnr(hhr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() )\n",
    "print(len(test_data))\n",
    "print(len(test_dataloders))\n",
    "# data_set.lon.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo:\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    import time\n",
    "    start=time.time()\n",
    "    print(\"test time for sigle day %s \" %(time.time()-start))\n",
    "\n",
    "    sr_numpy=sr.numpy()[7][0]\n",
    "#     sr_numpy=np.ascontiguousarray(sr_numpy.transpose((1, 0)))\n",
    "    data_sr=xr.DataArray(sr_numpy,coords=[data_set.lat.data,data_set.lon.data],dims=[\"lat\",\"lon\"])\n",
    "    \n",
    "    hr_numpy=hr.numpy()[7][0]\n",
    "#     hr_numpy=np.ascontiguousarray(hr_numpy.transpose((1, 0)))\n",
    "    data_hr=xr.DataArray(hr_numpy,coords=[data_set.lat.data,data_set.lon.data],dims=[\"lat\",\"lon\"])\n",
    "    print(date)\n",
    "    dpt.draw_aus(data_hr,\n",
    "                 colormap = plt.cm.get_cmap('RdBu_r', 10),\n",
    "                 title=\"super resolution we predicted\",\n",
    "                 save=False)\n",
    "    dpt.draw_aus(data_sr,\n",
    "                 colormap = plt.cm.get_cmap('RdBu_r', 10),\n",
    "                 title=\"super resolution we predicted\",\n",
    "                 save=False)\n",
    "\n",
    "# psnr1(sr, hr)\n",
    "# print(hr.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hr_numpy.shape)\n",
    "print(data_set.lon.data.shape)\n",
    "print(data_set.lat.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "\n",
    "\n",
    "\n",
    "epoch = self.scheduler.last_epoch + 1\n",
    "self.ckp.write_log('\\nEvaluation:')\n",
    "self.ckp.add_log(torch.zeros(1, len(self.scale)))\n",
    "self.model.eval()\n",
    "\n",
    "timer_test = utility.timer()\n",
    "with torch.no_grad():\n",
    "    for idx_scale, scale in enumerate(self.scale):\n",
    "        eval_acc = 0\n",
    "        self.loader_test.dataset.set_scale(idx_scale)\n",
    "        tqdm_test = tqdm(self.loader_test, ncols=80)\n",
    "        for idx_img, (lr, hr, filename, _) in enumerate(tqdm_test):\n",
    "            filename = filename[0]\n",
    "            no_eval = (hr.nelement() == 1)\n",
    "            if not no_eval:\n",
    "                lr, hr = self.prepare([lr, hr])\n",
    "            else:\n",
    "                lr = self.prepare([lr])[0]\n",
    "\n",
    "            sr = self.model(lr, idx_scale)\n",
    "            sr = utility.quantize(sr, self.args.rgb_range)\n",
    "\n",
    "            save_list = [sr]\n",
    "            if not no_eval:\n",
    "                eval_acc += utility.calc_psnr(\n",
    "                    sr, hr, scale, self.args.rgb_range,\n",
    "                    benchmark=self.loader_test.dataset.benchmark\n",
    "                )\n",
    "                save_list.extend([lr, hr])\n",
    "\n",
    "            if self.args.save_results:\n",
    "                self.ckp.save_results(filename, save_list, scale)\n",
    "\n",
    "        self.ckp.log[-1, idx_scale] = eval_acc / len(self.loader_test)\n",
    "        best = self.ckp.log.max(0)\n",
    "        self.ckp.write_log(\n",
    "            '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
    "                self.args.data_test,\n",
    "                scale,\n",
    "                self.ckp.log[-1, idx_scale],\n",
    "                best[0][idx_scale],\n",
    "                best[1][idx_scale] + 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "self.ckp.write_log(\n",
    "    'Total time: {:.2f}s\\n'.format(timer_test.toc()), refresh=True\n",
    ")\n",
    "if not self.args.test_only:\n",
    "    self.ckp.save(self, epoch, is_best=(best[1][0] + 1 == epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.new()\n",
    "np.random.rand(8, 4, 78, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "\n",
    "# channel=1\n",
    "# x=np.random.rand(8,channel, 78, 100)\n",
    "# x=x.astype(np.float32)\n",
    "# print(x.dtype)\n",
    "\n",
    "# means, stdevs = [], []\n",
    "\n",
    "# for i in range(channel):\n",
    "#     pixels = x[:, i, :, :].ravel()  # 拉成一行\n",
    "#     means.append(np.mean(pixels))\n",
    "#     stdevs.append(np.std(pixels))\n",
    "\n",
    "# x=torch.tensor(x)\n",
    "\n",
    "\n",
    "# # std=np.std(x.ravel(),axis=0)\n",
    "# # print(std.shape)\n",
    "# # mean=np.mean(x)\n",
    "# print(means)\n",
    "# print(stdevs)\n",
    "\n",
    "# # x=torch.rand((8, 3, 78, 100))\n",
    "# # std=torch.std(x)\n",
    "# # mean=torch.mean(x)\n",
    "\n",
    "# # x.dtype=\"float32\"\n",
    "\n",
    "# class MeanShift(nn.Conv2d):\n",
    "#     def __init__(self, rgb_range, rgb_mean, rgb_std,channels, sign=-1):\n",
    "#         super(MeanShift, self).__init__(channel, channel, kernel_size=1)\n",
    "#         std = torch.Tensor(rgb_std)\n",
    "#         self.weight.data = torch.eye(channel).view(channel, channel, 1, 1)\n",
    "#         self.weight.data.div_(std.view(channel, 1, 1, 1))\n",
    "#         self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean)\n",
    "#         self.bias.data.div_(std)\n",
    "#         self.requires_grad = False\n",
    "        \n",
    "# aa=MeanShift(1,means,stdevs,3)\n",
    "# # aa(x)\n",
    "# np.mean(aa(x).detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checkpoint = utility.checkpoint(args)\n",
    "# # net = model.Model(args, checkpoint)\n",
    "# # criterion = nn.L1Loss()\n",
    "# # optimizer_my = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
    "# def prepare( l, volatile=False):\n",
    "#     device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "#     def _prepare(tensor):\n",
    "#         if args.precision == 'half': tensor = tensor.half()\n",
    "#         return tensor.to(device)\n",
    "\n",
    "#     return [_prepare(_l) for _l in l]\n",
    "\n",
    "# max_error=10000\n",
    "# for e in range(args.epochs):\n",
    "#     if e % 10 == 0:\n",
    "#         for p in optimizer_my.param_groups:\n",
    "#             p['lr'] *= 0.9\n",
    "        \n",
    "#     net.train()\n",
    "#     for batch, (lr, hr) in enumerate(train_dataloders):\n",
    "#         lr, hr = prepare([lr, hr])\n",
    "# #         print(lr)\n",
    "\n",
    "#         optimizer_my.zero_grad()\n",
    "#         sr = net(lr, 0)\n",
    "# #         sr=utility.fit_size(sr,args)\n",
    "\n",
    "#         error = criterion(sr[:,:,:,0:403], hr)\n",
    "#         if error<max_error:\n",
    "#             max_error=error\n",
    "#             torch.save(net,\"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model/save/\"+str(e)+\".pkl\")\n",
    "#         error.backward()\n",
    "#         optimizer_my.step()\n",
    "#     print(\"epoche: %d, lr: %f, error: %f\"%(e,optimizer_my.state_dict()['param_groups'][0]['lr'],error.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end loading one data,time cost 1.715966\n",
    "end loading one data,time cost 1.632074\n",
    "end loading one data,time cost 1.671565\n",
    "end loading one data,time cost 1.715903\n",
    "end loading one data,time cost 1.605141\n",
    "end loading one data,time cost 1.621977\n",
    "end loading one data,time cost 1.621583\n",
    "end loading one data,time cost 1.621500\n",
    "end loading one data,time cost 1.600586\n",
    "end loading one data,time cost 1.594560\n",
    "end loading one data,time cost 1.593534\n",
    "end loading one data,time cost 1.604488\n",
    "end loading one data,time cost 1.606978\n",
    "end loading one data,time cost 1.600660\n",
    "end loading one data,time cost 1.600594\n",
    "end loading one data,time cost 1.605244\n",
    "end loading one data,time cost 1.692404\n",
    "end loading one data,time cost 1.619076\n",
    "end loading one data,time cost 1.682503\n",
    "end loading one data,time cost 1.620104\n",
    "end loading one data,time cost 1.628786\n",
    "end loading one data,time cost 1.607090\n",
    "end loading one data,time cost 1.670968\n",
    "end loading one data,time cost 1.671936\n",
    "end loading one data,time cost 1.602363\n",
    "end loading one data,time cost 1.654448\n",
    "end loading one data,time cost 1.673330\n",
    "end loading one data,time cost 1.623322\n",
    "end loading one data,time cost 1.635231\n",
    "end loading one data,time cost 1.642935\n",
    "end loading one data,time cost 1.650784\n",
    "end loading one data,time cost 1.645927\n",
    "end loading one data,time cost 1.726419\n",
    "end loading one data,time cost 1.690695\n",
    "end loading one data,time cost 1.689773\n",
    "end loading one data,time cost 1.711888\n",
    "end loading one data,time cost 1.612949\n",
    "end loading one data,time cost 1.617190\n",
    "end loading one data,time cost 1.640625\n",
    "end loading one data,time cost 1.674064\n",
    "end loading one data,time cost 1.642350\n",
    "end loading one data,time cost 1.647243\n",
    "end loading one data,time cost 1.606059\n",
    "end loading one data,time cost 1.593960\n",
    "end loading one data,time cost 1.629991\n",
    "end loading one data,time cost 1.602437\n",
    "end loading one data,time cost 1.647727\n",
    "end loading one data,time cost 1.660140\n",
    "end loading one data,time cost 1.712363\n",
    "end loading one data,time cost 1.706504\n",
    "end loading one data,time cost 1.684479\n",
    "end loading one data,time cost 1.705693\n",
    "end loading one data,time cost 1.656246\n",
    "end loading one data,time cost 1.632491\n",
    "end loading one data,time cost 1.641997\n",
    "end loading one data,time cost 1.640489\n",
    "end loading one data,time cost 1.615456\n",
    "end loading one data,time cost 1.657358\n",
    "end loading one data,time cost 1.619042\n",
    "end loading one data,time cost 1.591613\n",
    "end loading one data,time cost 1.642784\n",
    "end loading one data,time cost 1.649220\n",
    "end loading one data,time cost 1.614412\n",
    "end loading one data,time cost 1.629373\n",
    "end loading one data,time cost 1.681119\n",
    "end loading one data,time cost 1.661355\n",
    "end loading one data,time cost 1.656491\n",
    "end loading one data,time cost 1.663970\n",
    "end loading one data,time cost 1.660205\n",
    "end loading one data,time cost 1.646195\n",
    "end loading one data,time cost 1.666683\n",
    "end loading one data,time cost 1.668686\n",
    "end loading one data,time cost 1.625349\n",
    "end loading one data,time cost 1.636791\n",
    "end loading one data,time cost 1.644629\n",
    "end loading one data,time cost 1.653769\n",
    "end loading one data,time cost 1.667453\n",
    "end loading one data,time cost 1.653591\n",
    "end loading one data,time cost 1.660961\n",
    "end loading one data,time cost 1.613453\n",
    "end loading one data,time cost 1.696342\n",
    "end loading one data,time cost 1.649550\n",
    "end loading one data,time cost 1.633617\n",
    "end loading one data,time cost 1.665265\n",
    "end loading one data,time cost 1.657074\n",
    "end loading one data,time cost 1.632226\n",
    "end loading one data,time cost 1.695935\n",
    "end loading one data,time cost 1.654280\n",
    "end loading one data,time cost 1.635847\n",
    "end loading one data,time cost 1.608618\n",
    "end loading one data,time cost 1.642667\n",
    "end loading one data,time cost 1.651407\n",
    "end loading one data,time cost 1.668395\n",
    "end loading one data,time cost 1.671665\n",
    "end loading one data,time cost 1.657387\n",
    "end loading one data,time cost 1.668278\n",
    "end loading one data,time cost 1.723833\n",
    "end loading one data,time cost 1.661024\n",
    "end loading one data,time cost 1.662430\n",
    "end loading one data,time cost 1.684431\n",
    "end loading one data,time cost 1.645400\n",
    "end loading one data,time cost 1.617971\n",
    "end loading one data,time cost 1.611092\n",
    "end loading one data,time cost 1.622975\n",
    "end loading one data,time cost 1.649650\n",
    "end loading one data,time cost 1.641810\n",
    "end loading one data,time cost 1.656899\n",
    "end loading one data,time cost 1.656220\n",
    "end loading one data,time cost 1.665733\n",
    "end loading one data,time cost 1.688295\n",
    "end loading one data,time cost 1.658993\n",
    "end loading one data,time cost 1.674594\n",
    "end loading one data,time cost 1.703684\n",
    "end loading one data,time cost 1.704101\n",
    "end loading one data,time cost 1.638448\n",
    "end loading one data,time cost 1.674996\n",
    "end loading one data,time cost 1.631276\n",
    "end loading one data,time cost 1.634202\n",
    "end loading one data,time cost 1.636754\n",
    "end loading one data,time cost 1.702930\n",
    "end loading one data,time cost 1.654904\n",
    "end loading one data,time cost 1.643668\n",
    "end loading one data,time cost 1.663055\n",
    "end loading one data,time cost 1.641192\n",
    "end loading one data,time cost 1.652675\n",
    "end loading one data,time cost 1.675678\n",
    "end loading one data,time cost 1.642454\n",
    "end loading one data,time cost 1.672420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end loading one data,time cost 1.633667\n",
    "end loading one data,time cost 1.608869\n",
    "end loading one data,time cost 1.585573\n",
    "end loading one data,time cost 1.603048\n",
    "end loading one data,time cost 1.639884\n",
    "end loading one data,time cost 1.633841\n",
    "end loading one data,time cost 1.678963\n",
    "end loading one data,time cost 1.641207\n",
    "end loading one data,time cost 1.625344\n",
    "end loading one data,time cost 1.623207\n",
    "end loading one data,time cost 1.649238\n",
    "end loading one data,time cost 1.635630\n",
    "end loading one data,time cost 1.604664\n",
    "end loading one data,time cost 1.610379\n",
    "end loading one data,time cost 1.652588\n",
    "end loading one data,time cost 1.597581\n",
    "end loading one data,time cost 1.583224\n",
    "end loading one data,time cost 1.629541\n",
    "end loading one data,time cost 1.627871\n",
    "end loading one data,time cost 1.657890\n",
    "end loading one data,time cost 1.611370\n",
    "end loading one data,time cost 1.586311\n",
    "end loading one data,time cost 1.673285\n",
    "end loading one data,time cost 1.651267\n",
    "end loading one data,time cost 1.655988\n",
    "end loading one data,time cost 1.631040\n",
    "end loading one data,time cost 1.618624\n",
    "end loading one data,time cost 1.654610\n",
    "end loading one data,time cost 1.605169\n",
    "end loading one data,time cost 1.590393\n",
    "end loading one data,time cost 1.681857\n",
    "end loading one data,time cost 1.626186\n",
    "end loading one data,time cost 1.657457\n",
    "end loading one data,time cost 1.642736\n",
    "end loading one data,time cost 1.670448\n",
    "end loading one data,time cost 1.646338\n",
    "end loading one data,time cost 1.601079\n",
    "end loading one data,time cost 1.588476\n",
    "end loading one data,time cost 1.643233\n",
    "end loading one data,time cost 1.688879\n",
    "end loading one data,time cost 1.599864\n",
    "end loading one data,time cost 1.585036\n",
    "end loading one data,time cost 1.619789\n",
    "end loading one data,time cost 1.589529\n",
    "end loading one data,time cost 1.587214\n",
    "end loading one data,time cost 1.607371"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
