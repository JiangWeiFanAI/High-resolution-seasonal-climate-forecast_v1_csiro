{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "from args_parameter import args\n",
    "from PrepareData import ACCESS_v1\n",
    "\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "import utility\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import xarray as xr\n",
    "\n",
    "args.file_ACCESS_dir_pr=\"/g/data/ub7/access-s1/hc/raw_model/atmos/pr/daily/\"\n",
    "args.file_ACCESS_dir=\"/g/data/ub7/access-s1/hc/raw_model/atmos/\"\n",
    "\n",
    "file_BARRA_dir=\"/g/data/ma05/BARRA_R/analysis/acum_proc/\"\n",
    "args.channels=0\n",
    "if args.pr:\n",
    "    args.channels+=1\n",
    "if args.zg:\n",
    "    args.channels+=1\n",
    "if args.psl:\n",
    "    args.channels+=1\n",
    "if args.tasmax:\n",
    "    args.channels+=1\n",
    "if args.tasmin:\n",
    "    args.channels+=1\n",
    "access_rgb_mean= 2.9067910245780248e-05*86400\n",
    "\n",
    "leading_time=217\n",
    "leading_time_we_use=31\n",
    "\n",
    "\n",
    "init_date=date(1970, 1, 1)\n",
    "start_date=date(1990, 1, 2)\n",
    "end_date=date(1990,12,30) #if 929 is true we should substract 1 day\n",
    "dates=[start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "print(access_rgb_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5114674452354135\n"
     ]
    }
   ],
   "source": [
    "#for debuging on my computer\n",
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "from args_parameter import args\n",
    "from PrepareData import ACCESS_BARRA_v1,ACCESS_BARRA_v2\n",
    "\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "import utility\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import xarray as xr\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "\n",
    "# args.file_ACCESS_dir=\"E:/climate/access-s1/pr/daily/\"\n",
    "args.file_ACCESS_dir=\"H:/climate/access-s1/\"\n",
    "\n",
    "# args.file_BARRA_dir=\"C:/Users/JIA059/barra/\"\n",
    "args.file_BARRA_dir=\"D:/dataset/accum_prcp/\"\n",
    "\n",
    "args.channels=1\n",
    "args.batch_size=1\n",
    "\n",
    "# ensemble=['e01','e02']\n",
    "args.ensemble=2\n",
    "access_rgb_mean= 2.9067910245780248e-05*86400\n",
    "\n",
    "leading_time=217\n",
    "args.leading_time_we_use=1\n",
    "# args.lr=0.001\n",
    "\n",
    "init_date=date(1970, 1, 1)\n",
    "start_date=date(1990, 1, 2)\n",
    "end_date=date(1990,12,30) #if 929 is true we should substract 1 day\n",
    "dates=[start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "print(access_rgb_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> BARRA_R & ACCESS_S1 loading\n",
      "=> from 1990/01/02 to 1990/12/30\n",
      "Dataset statistics:\n",
      "  ------------------------------\n",
      "  total |    87\n",
      "  ------------------------------\n",
      "  train |    69\n",
      "  ------------------------------\n",
      "  val   |    18\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "#     transforms.Resize(IMG_SIZE),\n",
    "#     transforms.RandomResizedCrop(IMG_SIZE),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(30),\n",
    "    transforms.ToTensor()\n",
    "#     transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "])\n",
    "\n",
    "data_set=ACCESS_BARRA_v2(start_date,end_date,transform=train_transforms)\n",
    "train_data,val_data=random_split(data_set,[int(len(data_set)*0.8),len(data_set)-int(len(data_set)*0.8)])\n",
    "\n",
    "\n",
    "print(\"Dataset statistics:\")\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  total | %5d\"%len(data_set))\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  train | %5d\"%len(train_data))\n",
    "print(\"  ------------------------------\")\n",
    "print(\"  val   | %5d\"%len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloders =DataLoader(train_data,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        shuffle=False,\n",
    "                            num_workers=0)\n",
    "val_dataloders =DataLoader(val_data,\n",
    "                                        batch_size=args.batch_size,\n",
    "                                        shuffle=False,\n",
    "                          num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model...\n",
      "accesss-s1 mean (0.4690)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# args.pre_train =False\n",
    "# args.pre_train =\"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model/RCAN_BIX\"+str(args.scale[0])+\".pt\"\n",
    "# \"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model\"\n",
    "def prepare( l, volatile=False):\n",
    "    device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "    def _prepare(tensor):\n",
    "        if args.precision == 'half': tensor = tensor.half()\n",
    "        return tensor.to(device)\n",
    "\n",
    "    return [_prepare(_l) for _l in l]\n",
    "\n",
    "checkpoint = utility.checkpoint(args)\n",
    "net = model.Model(args, checkpoint).double()\n",
    "args.lr=0.001\n",
    "criterion = nn.L1Loss()\n",
    "optimizer_my = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer_my, step_size=7, gamma=0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_my, gamma=0.9)\n",
    "# torch.optim.lr_scheduler.MultiStepLR(optimizer_my, milestones=[20,80], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2511a69fc40>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(args.lr)\n",
    "# %matplotlib inline\n",
    "# lr_list = []\n",
    "# LR = 0.01\n",
    "# epoch=800\n",
    "# for epoch in range(100):\n",
    "#     scheduler.step()\n",
    "#     lr_list.append(optimizer_my.state_dict()['param_groups'][0]['lr'])\n",
    "# plt.plot(range(100),lr_list,color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 0,time cost 3.721063 s, lr: 0.001000, train_loss: 0.040629,validation loss:1.493536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                                    | 0/18 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 1,time cost 2.525884 s, lr: 0.001000, train_loss: 0.037651,validation loss:1.353961 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/18 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 2,time cost 2.506421 s, lr: 0.001000, train_loss: 0.034208,validation loss:1.245397 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5786c9c417ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mrunning_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0moptimizer_my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\Weifa\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\Weifa\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "training_name=\"temp01\"\n",
    "\n",
    "max_error=10000\n",
    "train_loss=np.inf\n",
    "for e in range(args.epochs):\n",
    "    #train\n",
    "    net.train()\n",
    "    loss=0\n",
    "    start=time.time()\n",
    "#     if e % 10 == 0:\n",
    "#         for p in optimizer_my.param_groups:\n",
    "#             p['lr'] *= 0.9\n",
    "\n",
    "    for batch, (lr, hr,_,_) in enumerate(train_dataloders):\n",
    "    #     print(batch, (lr.size(), hr.size()))\n",
    "        lr, hr = prepare([lr, hr])\n",
    "        optimizer_my.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            sr = net(lr, 0)\n",
    "#         error = criterion(sr[:,:,:,0:403], hr)\n",
    "            running_loss =criterion(sr, hr)\n",
    "            loss+=running_loss \n",
    "        running_loss.backward()\n",
    "        optimizer_my.step()\n",
    "        break\n",
    "        \n",
    "    #validation\n",
    "    net.eval()\n",
    "    start=time.time()\n",
    "    with torch.no_grad():\n",
    "        eval_psnr=0\n",
    "        eval_ssim=0\n",
    "        tqdm_val = tqdm(val_dataloders, ncols=80)\n",
    "        for idx_img, (lr, hr,date,_) in enumerate(tqdm_val):\n",
    "            lr, hr = prepare([lr, hr])\n",
    "            sr = net(lr, 0)\n",
    "            val_loss=criterion(sr, hr)\n",
    "            for ssr,hhr in zip(sr,hr):\n",
    "                eval_psnr+=compare_psnr(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "                eval_ssim+=compare_ssim(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )  \n",
    "            break    \n",
    "#             print(\"psnr: %f \"%(eval_psnr/len(test_data)))\n",
    "    print(\"epoche: %d,time cost %f s, lr: %f, train_loss: %f,validation loss:%f \"%(\n",
    "              e,\n",
    "              time.time()-start,\n",
    "              optimizer_my.state_dict()['param_groups'][0]['lr'],\n",
    "              running_loss.item()/len(train_data),\n",
    "              val_loss\n",
    "         ))\n",
    "    if train_loss<max_error:\n",
    "        max_error=train_loss\n",
    "        torch.save(net,\"\"+str(e)+\".pkl\")\n",
    "#             if not os.path.exists(\"./model/save/temp01/\"):\n",
    "#                 os.mkdir(\"./model/save/temp01/\")\n",
    "#             torch.save(net,\"./model/save/\"+training_name+\"/\"+str(e)+\".pkl\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"epoche: %d,time cost %f s, lr: %f, train_loss: %f,validation loss: %f\"%(e,time.time()-start,optimizer_my.state_dict()['param_groups'][0]['lr'],running_loss.item()/len(train_data), val_loss))\n",
    "train_loss=np.inf\n",
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing,and evaluation\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net.eval()\n",
    "start=time.time()\n",
    "with torch.no_grad():\n",
    "    eval_psnr=0\n",
    "    eval_ssim=0\n",
    "    tqdm_val = tqdm(val_dataloders, ncols=80)\n",
    "    for idx_img, (lr, hr,date,_) in enumerate(tqdm_val):\n",
    "        lr, hr = prepare([lr, hr])\n",
    "        sr = net(lr, 0)\n",
    "        val_loss=criterion(sr, hr)\n",
    "        for ssr,hhr in zip(sr,hr):\n",
    "            eval_psnr+=compare_psnr(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "            eval_ssim+=compare_ssim(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "            \n",
    "            \n",
    "            \n",
    "        break\n",
    "#     break\n",
    "            \n",
    "    print(\"psnr: %f \"%(eval_psnr/len(val_data)))\n",
    "        \n",
    "print(\"time cost: %f s \"%(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (len(test_dataloders)*args.batch_size )\n",
    "print(0+val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(hr.max()-hr.min()).item()\n",
    "print(\"psnr: %f \"%(hr.max()-hr.min()).item() )\n",
    "ssim_avg=0\n",
    "psnr_avg=0\n",
    "for ssr,hhr in zip(sr,hr):\n",
    "#     print(hhr[0].shape)\n",
    "#     print(compare_ssim(ssr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() ))\n",
    "    psnr_avg+=compare_psnr(ssr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() )\n",
    "    ssim_avg+=compare_ssim(ssr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() )\n",
    "print(ssim_avg/args.batch_size)\n",
    "print(psnr_avg/args.batch_size)\n",
    "compare_psnr(ssr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() )\n",
    "\n",
    "print(args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sr.shape,hr.shape)\n",
    "compare_psnr(hhr[0].numpy(),hhr[0].numpy(),data_range=(hhr[0].max()-hhr[0].min()).item() )\n",
    "print(len(test_data))\n",
    "print(len(test_dataloders))\n",
    "# data_set.lon.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo:\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    import time\n",
    "    start=time.time()\n",
    "    print(\"test time for sigle day %s \" %(time.time()-start))\n",
    "\n",
    "    sr_numpy=sr.numpy()[7][0]\n",
    "#     sr_numpy=np.ascontiguousarray(sr_numpy.transpose((1, 0)))\n",
    "    data_sr=xr.DataArray(sr_numpy,coords=[data_set.lat.data,data_set.lon.data],dims=[\"lat\",\"lon\"])\n",
    "    \n",
    "    hr_numpy=hr.numpy()[7][0]\n",
    "#     hr_numpy=np.ascontiguousarray(hr_numpy.transpose((1, 0)))\n",
    "    data_hr=xr.DataArray(hr_numpy,coords=[data_set.lat.data,data_set.lon.data],dims=[\"lat\",\"lon\"])\n",
    "    print(date)\n",
    "    dpt.draw_aus(data_hr,\n",
    "                 colormap = plt.cm.get_cmap('RdBu_r', 10),\n",
    "                 title=\"super resolution we predicted\",\n",
    "                 save=False)\n",
    "    dpt.draw_aus(data_sr,\n",
    "                 colormap = plt.cm.get_cmap('RdBu_r', 10),\n",
    "                 title=\"super resolution we predicted\",\n",
    "                 save=False)\n",
    "\n",
    "# psnr1(sr, hr)\n",
    "# print(hr.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hr_numpy.shape)\n",
    "print(data_set.lon.data.shape)\n",
    "print(data_set.lat.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "\n",
    "\n",
    "\n",
    "epoch = self.scheduler.last_epoch + 1\n",
    "self.ckp.write_log('\\nEvaluation:')\n",
    "self.ckp.add_log(torch.zeros(1, len(self.scale)))\n",
    "self.model.eval()\n",
    "\n",
    "timer_test = utility.timer()\n",
    "with torch.no_grad():\n",
    "    for idx_scale, scale in enumerate(self.scale):\n",
    "        eval_acc = 0\n",
    "        self.loader_test.dataset.set_scale(idx_scale)\n",
    "        tqdm_test = tqdm(self.loader_test, ncols=80)\n",
    "        for idx_img, (lr, hr, filename, _) in enumerate(tqdm_test):\n",
    "            filename = filename[0]\n",
    "            no_eval = (hr.nelement() == 1)\n",
    "            if not no_eval:\n",
    "                lr, hr = self.prepare([lr, hr])\n",
    "            else:\n",
    "                lr = self.prepare([lr])[0]\n",
    "\n",
    "            sr = self.model(lr, idx_scale)\n",
    "            sr = utility.quantize(sr, self.args.rgb_range)\n",
    "\n",
    "            save_list = [sr]\n",
    "            if not no_eval:\n",
    "                eval_acc += utility.calc_psnr(\n",
    "                    sr, hr, scale, self.args.rgb_range,\n",
    "                    benchmark=self.loader_test.dataset.benchmark\n",
    "                )\n",
    "                save_list.extend([lr, hr])\n",
    "\n",
    "            if self.args.save_results:\n",
    "                self.ckp.save_results(filename, save_list, scale)\n",
    "\n",
    "        self.ckp.log[-1, idx_scale] = eval_acc / len(self.loader_test)\n",
    "        best = self.ckp.log.max(0)\n",
    "        self.ckp.write_log(\n",
    "            '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
    "                self.args.data_test,\n",
    "                scale,\n",
    "                self.ckp.log[-1, idx_scale],\n",
    "                best[0][idx_scale],\n",
    "                best[1][idx_scale] + 1\n",
    "            )\n",
    "        )\n",
    "\n",
    "self.ckp.write_log(\n",
    "    'Total time: {:.2f}s\\n'.format(timer_test.toc()), refresh=True\n",
    ")\n",
    "if not self.args.test_only:\n",
    "    self.ckp.save(self, epoch, is_best=(best[1][0] + 1 == epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.new()\n",
    "np.random.rand(8, 4, 78, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "\n",
    "\n",
    "# channel=1\n",
    "# x=np.random.rand(8,channel, 78, 100)\n",
    "# x=x.astype(np.float32)\n",
    "# print(x.dtype)\n",
    "\n",
    "# means, stdevs = [], []\n",
    "\n",
    "# for i in range(channel):\n",
    "#     pixels = x[:, i, :, :].ravel()  # 拉成一行\n",
    "#     means.append(np.mean(pixels))\n",
    "#     stdevs.append(np.std(pixels))\n",
    "\n",
    "# x=torch.tensor(x)\n",
    "\n",
    "\n",
    "# # std=np.std(x.ravel(),axis=0)\n",
    "# # print(std.shape)\n",
    "# # mean=np.mean(x)\n",
    "# print(means)\n",
    "# print(stdevs)\n",
    "\n",
    "# # x=torch.rand((8, 3, 78, 100))\n",
    "# # std=torch.std(x)\n",
    "# # mean=torch.mean(x)\n",
    "\n",
    "# # x.dtype=\"float32\"\n",
    "\n",
    "# class MeanShift(nn.Conv2d):\n",
    "#     def __init__(self, rgb_range, rgb_mean, rgb_std,channels, sign=-1):\n",
    "#         super(MeanShift, self).__init__(channel, channel, kernel_size=1)\n",
    "#         std = torch.Tensor(rgb_std)\n",
    "#         self.weight.data = torch.eye(channel).view(channel, channel, 1, 1)\n",
    "#         self.weight.data.div_(std.view(channel, 1, 1, 1))\n",
    "#         self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean)\n",
    "#         self.bias.data.div_(std)\n",
    "#         self.requires_grad = False\n",
    "        \n",
    "# aa=MeanShift(1,means,stdevs,3)\n",
    "# # aa(x)\n",
    "# np.mean(aa(x).detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checkpoint = utility.checkpoint(args)\n",
    "# # net = model.Model(args, checkpoint)\n",
    "# # criterion = nn.L1Loss()\n",
    "# # optimizer_my = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)\n",
    "# def prepare( l, volatile=False):\n",
    "#     device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "#     def _prepare(tensor):\n",
    "#         if args.precision == 'half': tensor = tensor.half()\n",
    "#         return tensor.to(device)\n",
    "\n",
    "#     return [_prepare(_l) for _l in l]\n",
    "\n",
    "# max_error=10000\n",
    "# for e in range(args.epochs):\n",
    "#     if e % 10 == 0:\n",
    "#         for p in optimizer_my.param_groups:\n",
    "#             p['lr'] *= 0.9\n",
    "        \n",
    "#     net.train()\n",
    "#     for batch, (lr, hr) in enumerate(train_dataloders):\n",
    "#         lr, hr = prepare([lr, hr])\n",
    "# #         print(lr)\n",
    "\n",
    "#         optimizer_my.zero_grad()\n",
    "#         sr = net(lr, 0)\n",
    "# #         sr=utility.fit_size(sr,args)\n",
    "\n",
    "#         error = criterion(sr[:,:,:,0:403], hr)\n",
    "#         if error<max_error:\n",
    "#             max_error=error\n",
    "#             torch.save(net,\"C:/Users/JIA059/climate_v1_csiro/High-resolution-seasonal-climate-forecast_v1_csiro/model/save/\"+str(e)+\".pkl\")\n",
    "#         error.backward()\n",
    "#         optimizer_my.step()\n",
    "#     print(\"epoche: %d, lr: %f, error: %f\"%(e,optimizer_my.state_dict()['param_groups'][0]['lr'],error.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
